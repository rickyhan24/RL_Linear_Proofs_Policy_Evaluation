# Policy Evaluation for the world of Linear Equation Proofs

In this project, I considered applying reinforcement learning to the world of solving linear equations of the form ax+b=d.  This world is analogous to the gridworld often discussed in reinforcement learning.  The states are the equations themselves; for instance, 'ax+b=d' is the starting state and 'x = (d-b)/a' is the terminal state.  We move from one state to the next using algebraic properties such as the additive inverse property or the multiplicative inverse property.  Therefore, the algebraic properties are the actions.  Each state has a set of actions that can be taken from that state; in other words, there are a set of properties one can apply to a given equation at each step.  In this project, I selected only a few possible actions for each state to simplify matters.  The terminal state, which is the solution to the linear equation, is given a reward of 1; and, all the other states are given a reward of 0.  The iterative Bellman equation is used to find the values for each state, given a fixed policy.  
